{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SharedArray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b18a29eb0af6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mSharedArray\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'SharedArray'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import multiprocessing as mp\n",
    "import SharedArray as sa\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "\n",
    "\n",
    "def generate_clusters (k, n, d, max_value, deviation):\n",
    "    # generate n random points in d dimensions with elements in [-deviation, deviation]\n",
    "    points = np.random.uniform(low=-deviation, high=deviation, size=(n, d))\n",
    "    # generate k points in d dimensions with elements in [0, max_value]\n",
    "    centers = np.random.random((k, d))*max_value\n",
    "    # generate clusters: for each point, randomly select a center and add to it\n",
    "    for i, point in enumerate(points):\n",
    "        points[i] += random.choice(centers)\n",
    "    return points\n",
    "\n",
    "\n",
    "try:\n",
    "    centroids = sa.attach(\"shm://centroids\")\n",
    "except FileNotFoundError:\n",
    "    centroids = sa.create(\"shm://centroids\", 1)\n",
    "try:\n",
    "    points = sa.attach(\"shm://points\")\n",
    "except FileNotFoundError:\n",
    "    points = sa.create(\"shm://points\", 1)\n",
    "\n",
    "\n",
    "def assign_point(i, k = len(centroids)):\n",
    "    min_distance_index = float('nan')\n",
    "    min_distance = math.inf\n",
    "    # for each centroid\n",
    "    for j, centroid in enumerate(centroids):\n",
    "        if j > k:\n",
    "            break\n",
    "        # compute the euclidean distance between the i-th point and the j-th centroid\n",
    "        d = np.linalg.norm(points[i] - centroid)\n",
    "        if d < min_distance:\n",
    "            min_distance_index = j\n",
    "            min_distance = d\n",
    "    # update cluster assignment and distances\n",
    "    return min_distance, min_distance_index\n",
    "\n",
    "\n",
    "class CLUMPY:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            k,\n",
    "            file=None,\n",
    "            n=2000,\n",
    "            d=2,\n",
    "            max_value=600000,\n",
    "            deviation=400000,\n",
    "            delimiter=None,\n",
    "            iterations=100,\n",
    "            random_centroids=False,\n",
    "            processes = mp.cpu_count()):\n",
    "        \"\"\"\n",
    "        CLUMPY constructor.\n",
    "        :param k: number of clusters\n",
    "        :param file: input file. When None, generates random clusters. (default: None)\n",
    "        :param n: used when file=None. Number of generated points. (default: 2000)\n",
    "        :param d: used when file=None. Generated point's dimensions. (default: 2)\n",
    "        :param max_value: used when file=None. Max value for generated clusters centers (default: 600000)\n",
    "        :param deviation: used when file=None. Max distance from cluster center for each point (default: 400000)\n",
    "        :param delimiter: used when file!=None, used for numpy.loadtxt() (default: None)\n",
    "        :param iterations: number of k-means iterations (default: 100)\n",
    "        :param random_centroids: if True generate random seeds.If False, use k-means++ (serial version) (default: False)\n",
    "        :param processes: number of spawned processes (default: multiprocessing.cpu.count())\n",
    "\n",
    "        \"\"\"\n",
    "        global centroids, points\n",
    "        try:\n",
    "            sa.delete(\"centroids\")\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        try:\n",
    "            sa.delete(\"points\")\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "        if max_value is None:\n",
    "            max_value = 600000\n",
    "        if deviation is None:\n",
    "            deviation = 400000\n",
    "        if iterations is None:\n",
    "            iterations = 100\n",
    "        if random_centroids is None:\n",
    "            random_centroids = False\n",
    "        if processes is None:\n",
    "            mp.cpu_count()\n",
    "\n",
    "        self.__file=file\n",
    "        self.__k = k\n",
    "        self.__iterations = iterations\n",
    "        self.__random_centroids = random_centroids\n",
    "        self.__colors = \\\n",
    "            cm.rainbow(np.linspace(0, 1, self.__k))     # colors[i] = color of the i-th cluster\n",
    "        self.__processes = processes\n",
    "        if file:\n",
    "            # if file is specified, read points from file\n",
    "            print(\"Reading {}...\".format(file))\n",
    "            points_copy = np.loadtxt(file, delimiter=delimiter)        # data points\n",
    "            (self.__n, self.__d) = points_copy.shape\n",
    "        else:\n",
    "            # otherwise generate n clusterized points in d dimensions\n",
    "            if not n or not d:\n",
    "                raise ValueError(\"missing n={} or d={}\".format(n, d))\n",
    "            self.__n = n\n",
    "            self.__d = d\n",
    "            print(\"Generating {} random points in {} dimensions...\".format(n, d))\n",
    "            points_copy = generate_clusters(k, self.__n, d, max_value, deviation)\n",
    "        centroids = sa.create(\"shm://centroids\", (k, self.__d))\n",
    "        points = sa.create(\"shm://points\", (self.__n,self.__d))\n",
    "        np.copyto(points, points_copy)\n",
    "        self.__d = points.shape[1]       # points dimensions\n",
    "        self.__n = points.shape[0]       # number of data points\n",
    "        # class[i] = j : the i-th data point is assigned to the j-th cluster\n",
    "        self.__class = np.full(self.__n, -1, dtype=np.int16)\n",
    "        # energy[i] : energy of the i-th cluster\n",
    "        self.__energy = np.zeros(k)\n",
    "        self.__distances = np.zeros(self.__n)\n",
    "        self.__clusters_size = np.zeros(self.__k, dtype=np.int32) # number of points assigned to each cluster\n",
    "        self.__clusters_sum = np.zeros((k, self.__d)) # sum of all vectors assigned to each cluster\n",
    "        # sanity checks\n",
    "        if self.__n < k:\n",
    "            raise ValueError(\"Number of clusters k={} is smaller than number of data points n={}\".format(k, self.__n))\n",
    "        if self.__d < 2:\n",
    "            raise ValueError(\"data points must have at least two dimensions\")\n",
    "        print(\"{} points in {} dimensions.\".format(self.__n, self.__d))\n",
    "        print(\"Generating seeds...\")\n",
    "        if random_centroids:\n",
    "            # generate k random indexes\n",
    "            random_indexes = list(range(self.__n))\n",
    "            random.shuffle(random_indexes)\n",
    "            # we decide centroids by randomly picking up data points\n",
    "            for i in range(k):\n",
    "                centroids[i] = points[random_indexes[i]]\n",
    "        else:\n",
    "            # k-means++\n",
    "            # step 1: select a random point as first centroid\n",
    "            centroids[0] = random.choice(points)\n",
    "            for i in range(1,k):\n",
    "                # step 2: asssign each point to the closest centroid (read only the first i elements in centroids)\n",
    "                results = [assign_point(j, i) for j in range(self.__n)]\n",
    "                # step 3: normalize distances\n",
    "                distances = [result[0] for result in results]\n",
    "                norm = [d/sum(distances) for d in distances]\n",
    "                # step 4: generate an uniform random number in [0,1]\n",
    "                r = np.random.uniform()\n",
    "                # step 5: choose the first element in norm that is greater or equal than r\n",
    "                acc = 0\n",
    "                chosen_index = 0\n",
    "                for n in norm:\n",
    "                    acc += n\n",
    "                    if acc >= r:\n",
    "                        break\n",
    "                    chosen_index += 1\n",
    "                centroids[i] = points[chosen_index]\n",
    "\n",
    "    def plot(self):\n",
    "        print(\"Plotting...\")\n",
    "        points_to_plot = np.concatenate((centroids, points), axis=0)\n",
    "        if self.__d > 2:\n",
    "            point_norm = (points_to_plot - points_to_plot.min())/(points_to_plot.max() - points_to_plot.min())\n",
    "            pca = sklearnPCA(n_components=2)  # 2-dimensional PCA\n",
    "            points_to_plot = np.array(pca.fit_transform(point_norm))\n",
    "        for i, (X, Y) in enumerate(points_to_plot):\n",
    "            if i<self.__k:\n",
    "                plt.scatter(X, Y, c=self.__colors[i], s=100, marker=\"^\")\n",
    "            else:\n",
    "                plt.scatter(X, Y, c=self.__colors[self.__class[i-self.__k]])\n",
    "        plt.show()\n",
    "\n",
    "    def cluster(self):\n",
    "        global centroids\n",
    "        with mp.Pool(self.__processes) as pool:\n",
    "            for iteration in range(self.__iterations):\n",
    "                # update each assignment: if no point changed its cluster, then we have reached the optimum\n",
    "                # for each datapoint\n",
    "                t = time.time()\n",
    "                results = pool.map(assign_point, range(self.__n))\n",
    "                assignment_time = time.time() - t\n",
    "                t = time.time()\n",
    "                for i, (min_distance, min_distance_index) in enumerate(results):\n",
    "                    # update cluster assignment and distances\n",
    "                    if min_distance_index != self.__class[i]:\n",
    "                        if self.__class[i] != -1:\n",
    "                            self.__clusters_size[self.__class[i]] -= 1\n",
    "                            self.__clusters_sum[self.__class[i]] -= points[i]\n",
    "                            self.__energy[self.__class[i]] -= self.__distances[i]\n",
    "                        self.__class[i] = min_distance_index\n",
    "                        self.__clusters_size[min_distance_index] += 1\n",
    "                        self.__clusters_sum[min_distance_index] += points[i]\n",
    "                        self.__distances[i] = min_distance ** 2\n",
    "                        self.__energy[min_distance_index] += self.__distances[i]\n",
    "                # update centroids\n",
    "                centroids_unchanged = True\n",
    "                for i in range(self.__k):\n",
    "                    new_centroid = self.__clusters_sum[i] / self.__clusters_size[i]\n",
    "                    centroids_unchanged = centroids_unchanged and np.array_equal(new_centroid, centroids[i])\n",
    "                    centroids[i] = new_centroid\n",
    "                print(\"iteration {} assignment={} updating={}\".format(iteration, assignment_time, time.time() - t))\n",
    "                if centroids_unchanged:\n",
    "                    print(\"Centroids unchanged, terminating...\")\n",
    "                    break\n",
    "            else:\n",
    "                print(\"Iterations finished!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"k\", help=\"number of clusters\", type=int)\n",
    "    parser.add_argument(\"--file\", help=\"input file. If not set, generates random clusters\")\n",
    "    parser.add_argument(\"--n\", help=\"used when file is not set. Number of generated points. (default: 2000)\", type=int)\n",
    "    parser.add_argument(\"--d\", help=\"used when file is not set. Generated point's dimensions. (default: 2)\", type=int)\n",
    "    parser.add_argument(\"--max_value\",\n",
    "                        help=\"used when file is not set. Max value for generated clusters centers (default: 600000)\",\n",
    "                        type=int)\n",
    "    parser.add_argument(\"--deviation\",\n",
    "                        help=\"used when file is not set. Max distance \"\n",
    "                             \"from cluster center for each point(default: 400000)\",\n",
    "                        type=int)\n",
    "    parser.add_argument(\"--delimiter\", help=\"used when file is set, used for numpy.loadtxt()\")\n",
    "    parser.add_argument(\"--iterations\", help=\"number of k-means iterations (default: 100)\", type=int)\n",
    "    parser.add_argument(\"--random_centroids\", help=\"if True generate random seeds.\"\n",
    "                        \"If False, use k-means++ (serial version) (default: False)\", type=bool)\n",
    "    parser.add_argument(\"--processes\", help=\"number of spawned processes (default: multiprocessing.cpu.count())\",\n",
    "                        type=int)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    k = args.k\n",
    "    random_centroids = args.random_centroids\n",
    "    processes = args.processes\n",
    "\n",
    "    if args.file:\n",
    "        clumpy = CLUMPY(k=k, file=args.file, delimiter=args.delimiter,\n",
    "                        random_centroids=random_centroids, processes=processes)\n",
    "    else:\n",
    "        clumpy = CLUMPY(k=k, n=args.n, d=args.d, max_value=args.max_value, deviation=args.deviation,\n",
    "                        delimiter=args.delimiter, iterations=args.iterations, random_centroids=random_centroids,\n",
    "                        processes=processes)\n",
    "\n",
    "    clumpy.cluster()\n",
    "    clumpy.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
